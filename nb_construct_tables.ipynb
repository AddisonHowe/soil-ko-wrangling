{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ccece7b",
   "metadata": {},
   "source": [
    "# Construct tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0156a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import functools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bc3c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTER_READ_STEALERS = True\n",
    "CLOSE_PLOTS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c692c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTDIRBASE = \"out/res_optimal\"\n",
    "\n",
    "OUTDIR = f\"{OUTDIRBASE}/tables\"\n",
    "IMGDIR = f\"{OUTDIRBASE}/images\"\n",
    "\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "os.makedirs(IMGDIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0816046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOILS = [\n",
    "    'Soil3', 'Soil5', 'Soil6', 'Soil9', 'Soil11', \n",
    "    'Soil12', 'Soil14', 'Soil15', 'Soil16', 'Soil17'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce25650a",
   "metadata": {},
   "outputs": [],
   "source": [
    "READ_STEALERS_FPATH = \"read_stealers.tsv\"\n",
    "df_read_stealers = pd.read_csv(\n",
    "    READ_STEALERS_FPATH,\n",
    "    sep=\"\\t\"\n",
    ")\n",
    "df_read_stealers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2098961f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DMD_TOPHITS_FPATH = f\"{OUTDIRBASE}/dmnd_combined_top_hits.tsv\"\n",
    "df_dmd_tophits = pd.read_csv(\n",
    "    DMD_TOPHITS_FPATH,\n",
    "    sep=\"\\t\",\n",
    ")\n",
    "df_dmd_tophits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4cec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "KO_INFO_FPATH = \"data/ko_information.tsv\"\n",
    "DF_KO_INFO = pd.read_csv(\n",
    "    KO_INFO_FPATH, sep=\"\\t\", index_col=0\n",
    ")\n",
    "\n",
    "def _mapfunc(s):\n",
    "    s = s.lower()\n",
    "    if \"nitrate reductase\" in s:\n",
    "        return \"nitrate reductase\"\n",
    "    elif \"nitrite reductase\" in s:\n",
    "        return \"nitrite reductase\"\n",
    "    elif \"nitric oxide reductase\" in s:\n",
    "        return \"nitric oxide reductase\"\n",
    "    elif \"nitrous oxide reductase\" in s or \"nitrous-oxide reductase\" in s:\n",
    "        return \"nitrous oxide reductase\"\n",
    "    elif \"hydroxylamine reductase\" in s:\n",
    "        return \"hydroxylamine reductase\"\n",
    "    else:\n",
    "        return \"other\"\n",
    "    \n",
    "DF_KO_INFO[\"category\"] = DF_KO_INFO[\"NAME\"].apply(_mapfunc)\n",
    "\n",
    "KO_LIST = list(DF_KO_INFO.index)\n",
    "\n",
    "DF_KO_INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aee9425",
   "metadata": {},
   "outputs": [],
   "source": [
    "KO_CATEGORIES = sorted(DF_KO_INFO[\"category\"].unique())\n",
    "KO_CATEGORY_SETS = {\n",
    "    cat: DF_KO_INFO[DF_KO_INFO[\"category\"] == cat].index.values\n",
    "    for cat in KO_CATEGORIES\n",
    "}\n",
    "for k, v in KO_CATEGORY_SETS.items():\n",
    "    print(f\"{k}:\\n{v}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b89029",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAXA_INFO_FPATH = \"data/taxid_to_scaffold.csv\"\n",
    "\n",
    "TAXA_DF = pd.read_csv(TAXA_INFO_FPATH)\n",
    "TAXA_LIST = list(TAXA_DF[~pd.isna(TAXA_DF[\"taxid\"])][\"taxid\"].values)\n",
    "\n",
    "TAXA_DF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094973a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "COVERAGE_DIR = \"data/coverage_arrays\"\n",
    "\n",
    "coverage_filelist = os.listdir(COVERAGE_DIR)\n",
    "coverage_filelist = [f for f in coverage_filelist if f.endswith(\".npz\")]\n",
    "\n",
    "print(f\"coverage files ({(len(coverage_filelist))}):\", coverage_filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd151f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ids = [\n",
    "    covfile.removeprefix(\"coverage_arrays_\").removesuffix(\".npz\")\n",
    "    for covfile in coverage_filelist\n",
    "]\n",
    "print(f\"sample ids ({(len(sample_ids))}):\", sample_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13f919a",
   "metadata": {},
   "source": [
    "### Accepted Reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824798db",
   "metadata": {},
   "outputs": [],
   "source": [
    "KO_TABLE_DIR = \"data/ko_tables\"\n",
    "\n",
    "data_rows = {}\n",
    "for f in [f for f in os.listdir(KO_TABLE_DIR) if f.endswith(\".tsv\")]:\n",
    "    with open(f\"{KO_TABLE_DIR}/{f}\", \"r\") as f:\n",
    "        csvreader = csv.reader(f, delimiter=\"\\t\")\n",
    "        header = next(csvreader)\n",
    "        for row in csvreader:  # process each row\n",
    "            sample_id, ko, avg_depth = row[0:3]\n",
    "            if sample_id not in data_rows:\n",
    "                data_rows[sample_id] = {}\n",
    "            if ko in KO_LIST:\n",
    "                data_rows[sample_id][ko] = avg_depth\n",
    "\n",
    "# Convert nested dict â†’ DataFrame\n",
    "df_full = pd.DataFrame.from_dict(data_rows, orient=\"index\", dtype=float)\n",
    "\n",
    "# Optional: ensure columns follow KO_LIST order\n",
    "df_full = df_full.reindex(columns=KO_LIST)\n",
    "\n",
    "# Ensure all sample_ids appear as rows\n",
    "all_sample_ids = set(df_full.index.values)\n",
    "missing_samples = [s for s in all_sample_ids if s not in sample_ids]\n",
    "df_full = df_full.reindex(all_sample_ids)\n",
    "# Fill nan values\n",
    "df_full = df_full.fillna(0.)\n",
    "\n",
    "print(len(df_full))\n",
    "df_full = df_full.drop(index=missing_samples)  # DROP PROBLEM SAMPLE\n",
    "\n",
    "print(len(df_full))\n",
    "for sample_id in missing_samples:\n",
    "    all_sample_ids.remove(sample_id)\n",
    "print(f\"Dropped {missing_samples}\")\n",
    "\n",
    "# Add boolean screens for CHL+/-, T0/T9, Nitrate/No_Nitrate\n",
    "screen_df = pd.DataFrame({\n",
    "    \"no_nitrate\": df_full.index.str.contains(\"No_Nitrate\"),\n",
    "    \"nitrate\": ~df_full.index.str.contains(\"No_Nitrate\"),\n",
    "    \"t0\": df_full.index.str.contains(\"T0\"),\n",
    "    \"t9\": df_full.index.str.contains(\"T9\"),\n",
    "    \"chl_pos\": df_full.index.str.contains(\"CHL\"),\n",
    "    \"chl_neg\": df_full.index.str.contains(\"None\"),\n",
    "}, index=df_full.index)\n",
    "\n",
    "# Prepend these to the KO columns\n",
    "nscreens = screen_df.shape[1]\n",
    "print(f\"{nscreens} screen columns\")\n",
    "df_full = pd.concat([screen_df, df_full], axis=1)\n",
    "df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd248ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "##  Construct sample subsets satisfying conditions of interest\n",
    "\n",
    "sample_subsets = {}\n",
    "print(f\"{len(all_sample_ids)} total samples\")\n",
    "\n",
    "sample_subsets[\"no_nitrate\"] = sorted(list(filter(\n",
    "    lambda s: \"No_Nitrate\" in s, \n",
    "    all_sample_ids\n",
    ")))\n",
    "print(f\"{len(sample_subsets[\"no_nitrate\"])} no-nitrate samples\")\n",
    "\n",
    "sample_subsets[\"t0_samples\"] = sorted(list(filter(\n",
    "    lambda s: (\"T0\" in s) and (\"No_Nitrate\" not in s),\n",
    "    all_sample_ids\n",
    ")))\n",
    "print(f\"{len(sample_subsets[\"t0_samples\"])} T0 samples\")\n",
    "\n",
    "sample_subsets[\"chl_pos_samples\"] = sorted(list(filter(\n",
    "    lambda s: (\"T9\" in s) and (\"No_Nitrate\" not in s) and (\"CHL\" in s),\n",
    "    all_sample_ids\n",
    ")))\n",
    "print(f\"{len(sample_subsets[\"chl_pos_samples\"])} T9 CHL+ samples\")\n",
    "\n",
    "sample_subsets[\"chl_neg_samples\"] = sorted(list(filter(\n",
    "    lambda s: (\"T9\" in s) and (\"No_Nitrate\" not in s) and (\"None\" in s),\n",
    "    all_sample_ids\n",
    ")))\n",
    "print(f\"{len(sample_subsets[\"chl_neg_samples\"])} T9 CHL- samples\")\n",
    "\n",
    "assert len(all_sample_ids) == len(functools.reduce(\n",
    "    lambda x, y: x | y, (set(v) for v in sample_subsets.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fc6f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "##  Dataframe subsets\n",
    "\n",
    "DF_SAMP_SUBSETS_ACCEPTED = {}\n",
    "for k in [\"t0_samples\", \"chl_pos_samples\", \"chl_neg_samples\", \"no_nitrate\"]:\n",
    "    DF_SAMP_SUBSETS_ACCEPTED[k] = df_full.loc[sample_subsets[k],:]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244dd4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_SAMP_SUBSETS_ACCEPTED[\"t0_samples\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8503e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_SAMP_SUBSETS_ACCEPTED[\"chl_pos_samples\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e912f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_SAMP_SUBSETS_ACCEPTED[\"chl_neg_samples\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bba6b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_SAMP_SUBSETS_ACCEPTED[\"no_nitrate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4d94f1",
   "metadata": {},
   "source": [
    "## Tables for rejected reads\n",
    "\n",
    "### Aggregate over taxa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c8e665",
   "metadata": {},
   "outputs": [],
   "source": [
    "KO_REJECTED_SUBSETS_DIR = f\"{OUTDIRBASE}/ko_expression\"\n",
    "\n",
    "contam_dfs = {}\n",
    "for sample_id, fname in zip(sample_ids, coverage_filelist):\n",
    "    fpath = os.path.join(KO_REJECTED_SUBSETS_DIR, fname)\n",
    "    fpath = fpath.replace(\"coverage_arrays_\", \"coverage_\")\n",
    "    fpath = fpath.replace(\".npz\", \".csv\")\n",
    "    df = pd.read_csv(os.path.join(fpath))\n",
    "    if FILTER_READ_STEALERS:\n",
    "        df = df[df[\"name\"].isin(df_read_stealers[\"sseqid\"])]\n",
    "    contam_dfs[sample_id] = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495a088e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9283d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_SAMP_SUBSETS_REJECTED = {}\n",
    "for key in DF_SAMP_SUBSETS_ACCEPTED:\n",
    "    print(key)\n",
    "    df_rej = DF_SAMP_SUBSETS_ACCEPTED[key].copy()\n",
    "    df_rej.iloc[:,nscreens:] = np.nan\n",
    "    ko_values_rej = {\n",
    "        sample_id: df.groupby(\"ko\")[\"avg_depth\"].sum()\n",
    "        for sample_id, df in contam_dfs.items()\n",
    "    }\n",
    "\n",
    "    for sample_id, series in ko_values_rej.items():\n",
    "        if sample_id in df_rej.index:\n",
    "            for ko, value in series.items():\n",
    "                if ko in df_rej.columns:\n",
    "                    df_rej.at[sample_id, ko] = value\n",
    "    \n",
    "    DF_SAMP_SUBSETS_REJECTED[key] = df_rej\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44502bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_SAMP_SUBSETS_REJECTED[\"t0_samples\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df294ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_SAMP_SUBSETS_REJECTED[\"chl_pos_samples\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26ea7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_SAMP_SUBSETS_REJECTED[\"chl_neg_samples\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96e85dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_SAMP_SUBSETS_REJECTED[\"no_nitrate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a99de5",
   "metadata": {},
   "source": [
    "## Plots and tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aca34e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_violin_plot(\n",
    "        df_subsets, \n",
    "        ko_set,\n",
    "        keys,\n",
    "        ko_labels=None,\n",
    "        width=None,\n",
    "        spacing=None,\n",
    "        gap=None,\n",
    "        margin=0,\n",
    "        legend=True,\n",
    "        legend_labels=None, \n",
    "        colors=None,\n",
    "        alpha=None,\n",
    "        hatch=None,\n",
    "        ax=None,\n",
    "        verbosity=1,\n",
    "        **kwargs\n",
    "):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=kwargs.get(\"figsize\", (8, 10)))\n",
    "\n",
    "    n = len(ko_set)\n",
    "    k = len(keys)\n",
    "\n",
    "    width = width if width else 0.9 * (1 / k) # width of violin\n",
    "    d = spacing if spacing else 0.01 * (1 / k)  # spacing between violins\n",
    "    gap = gap if gap else 0.5 * (1 / k)  # gap between KO groups\n",
    "\n",
    "    legend_handles = []\n",
    "    legend_labels = keys if legend_labels is None else legend_labels\n",
    "    ko_group_width = k * width + (k - 1) * d\n",
    "    for i, key in enumerate(keys):\n",
    "        df = df_subsets[key]\n",
    "        data = [np.log10(1+df[col]) for col in ko_set]\n",
    "        pos = margin + np.arange(n) * (ko_group_width + gap) + i * (width + d)\n",
    "        li = ax.violinplot(\n",
    "            data, pos, \n",
    "            orientation=\"horizontal\",\n",
    "            # showmeans=True, \n",
    "            showmedians=True, \n",
    "            showextrema=True,\n",
    "            widths=width,\n",
    "        )\n",
    "        if isinstance(colors, list):\n",
    "            c = colors[i]\n",
    "            for body in li[\"bodies\"]:\n",
    "                body.set_facecolor(c)\n",
    "                body.set_edgecolor(c)\n",
    "            for partname in ['cbars','cmins','cmaxes','cmeans','cmedians']:\n",
    "                if partname in li:\n",
    "                    vp = li[partname]\n",
    "                    vp.set_edgecolor(c)\n",
    "        \n",
    "        for body in li[\"bodies\"]:\n",
    "            if hatch:\n",
    "                body.set_hatch(hatch)\n",
    "            if alpha:\n",
    "                body.set_alpha(alpha)\n",
    "        \n",
    "        legend_handles.append(li[\"bodies\"][0])\n",
    "    \n",
    "    if legend:\n",
    "        if ax.get_legend() is None:\n",
    "            old_handles, old_labels = [], []\n",
    "        else:\n",
    "            old_handles = ax.get_legend().legend_handles\n",
    "            old_labels = [t.get_text() for t in ax.get_legend().texts]\n",
    "        legend_handles.reverse()\n",
    "        legend_labels.reverse()\n",
    "        all_handles = old_handles + legend_handles\n",
    "        all_labels = old_labels + legend_labels\n",
    "        ax.legend(\n",
    "            all_handles, all_labels,\n",
    "            bbox_to_anchor=(1.05, 1),\n",
    "            loc=\"upper left\"\n",
    "        )\n",
    "\n",
    "    # Set xticks\n",
    "    xticklabels = np.array(\n",
    "        [10**i for i in range(0, int(np.ceil(ax.get_xlim()[1])))]\n",
    "    )\n",
    "    ax.set_xticks(np.log10(1 + xticklabels), labels=xticklabels)\n",
    "\n",
    "    # Set yticks\n",
    "    yticks = margin + np.arange(n) * (ko_group_width + gap) + (ko_group_width - width) / 2 \n",
    "    ax.set_yticks(\n",
    "        yticks, \n",
    "        labels=ko_labels,\n",
    "    )\n",
    "\n",
    "    # Add labels and title\n",
    "    ax.set_xlabel(\"total avg depth\")\n",
    "    ax.set_ylabel(\"KO\")\n",
    "    ax.set_title(\"\")\n",
    "    ax.set_ylim(-gap, pos.max() + gap)\n",
    "    \n",
    "    return ax\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2c3675",
   "metadata": {},
   "source": [
    "#### Accepted reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8128c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_acc = [\"g\", \"b\", \"r\"]\n",
    "colors_rej = [\"brown\", \"cyan\", \"orange\"]\n",
    "\n",
    "alpha_acc = None\n",
    "alpha_rej = None\n",
    "\n",
    "hatch_acc = None\n",
    "hatch_rej = \"///\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a98035",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in DF_SAMP_SUBSETS_ACCEPTED:\n",
    "    df = DF_SAMP_SUBSETS_ACCEPTED[key]\n",
    "    df.iloc[:,nscreens:].to_csv(\n",
    "        f\"{OUTDIR}/{key}_accepted.csv\", float_format=\"%.3f\", na_rep=np.nan\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff277739",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "##  Violin plots (ACCEPTED)\n",
    "\n",
    "for category in KO_CATEGORIES:\n",
    "    ko_set = KO_CATEGORY_SETS[category]\n",
    "    ko_labels = [ko + \"\\n\" + DF_KO_INFO.loc[ko, \"SYMBOL\"] for ko in ko_set]\n",
    "    keys = [\"t0_samples\", \"chl_pos_samples\", \"chl_neg_samples\",]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=[8,10])\n",
    "\n",
    "    make_violin_plot(\n",
    "        DF_SAMP_SUBSETS_ACCEPTED, ko_set, keys, \n",
    "        ko_labels=ko_labels,\n",
    "        ax=ax,\n",
    "        colors=colors_acc,\n",
    "        alpha=alpha_acc,\n",
    "        hatch=hatch_acc,\n",
    "    )\n",
    "\n",
    "    ax.set_title(f\"{category} (accepted)\")\n",
    "\n",
    "    saveas = f\"{IMGDIR}/{category.replace(\" \", \"_\")}_accepted.png\"\n",
    "    print(f\"Saving {saveas}\")\n",
    "    plt.savefig(saveas, bbox_inches=\"tight\")\n",
    "    if CLOSE_PLOTS:\n",
    "        plt.close()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1357e3a0",
   "metadata": {},
   "source": [
    "#### Rejected reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da47e5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in DF_SAMP_SUBSETS_REJECTED:\n",
    "    df = DF_SAMP_SUBSETS_REJECTED[key]\n",
    "    df.iloc[:,nscreens:].to_csv(\n",
    "        f\"{OUTDIR}/{key}_rejected.csv\", float_format=\"%.3f\", na_rep=np.nan\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252d4235",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "##  Violin plots (REJECTED)\n",
    "\n",
    "for category in KO_CATEGORIES:\n",
    "    ko_set = KO_CATEGORY_SETS[category]\n",
    "    ko_labels = [ko + \"\\n\" + DF_KO_INFO.loc[ko, \"SYMBOL\"] for ko in ko_set]\n",
    "    keys = [\"t0_samples\", \"chl_pos_samples\", \"chl_neg_samples\",]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=[8,10])\n",
    "\n",
    "    make_violin_plot(\n",
    "        DF_SAMP_SUBSETS_REJECTED, ko_set, keys, \n",
    "        ko_labels=ko_labels,\n",
    "        ax=ax,\n",
    "        colors=colors_rej,\n",
    "        alpha=alpha_rej,\n",
    "        hatch=hatch_rej,\n",
    "    )\n",
    "\n",
    "    ax.set_title(f\"{category} (rejected)\")\n",
    "    \n",
    "    saveas = f\"{IMGDIR}/{category.replace(\" \", \"_\")}_rejected.png\"\n",
    "    print(f\"Saving {saveas}\")\n",
    "    plt.savefig(saveas, bbox_inches=\"tight\")\n",
    "    if CLOSE_PLOTS:\n",
    "        plt.close()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6967825e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_SAMP_SUBSETS_REJECTED[\"no_nitrate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893da4d6",
   "metadata": {},
   "source": [
    "### Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436ac6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_SAMP_SUBSETS_REJECTED.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676dd401",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "##  Violin plots (COMBINED)\n",
    "\n",
    "for category in KO_CATEGORIES:\n",
    "    ko_set = KO_CATEGORY_SETS[category]\n",
    "    ko_labels = [ko + \"\\n\" + DF_KO_INFO.loc[ko, \"SYMBOL\"] for ko in ko_set]\n",
    "    keys = [\"t0_samples\", \"chl_pos_samples\", \"chl_neg_samples\",]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8,10))\n",
    "\n",
    "    make_violin_plot(\n",
    "        DF_SAMP_SUBSETS_ACCEPTED, ko_set, keys, \n",
    "        ko_labels=ko_labels,\n",
    "        ax=ax,\n",
    "        legend=True,\n",
    "        legend_labels=[k + \" (accepted)\" for k in keys],\n",
    "        colors=colors_acc,\n",
    "        alpha=alpha_acc,\n",
    "        hatch=hatch_acc,\n",
    "    )\n",
    "\n",
    "    make_violin_plot(\n",
    "        DF_SAMP_SUBSETS_REJECTED, ko_set, keys, \n",
    "        ko_labels=ko_labels,\n",
    "        ax=ax,\n",
    "        legend=True,\n",
    "        legend_labels=[k + \" (rejected)\" for k in keys],\n",
    "        colors=colors_rej,\n",
    "        alpha=alpha_rej,\n",
    "        hatch=hatch_rej,\n",
    "    )\n",
    "\n",
    "    ax.set_title(f\"{category} (accepted vs rejected)\")\n",
    "\n",
    "    saveas = f\"{IMGDIR}/{category.replace(\" \", \"_\")}_comparison.png\"\n",
    "    print(f\"Saving {saveas}\")\n",
    "    plt.savefig(saveas, bbox_inches=\"tight\")\n",
    "    if CLOSE_PLOTS:\n",
    "        plt.close()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02eb414",
   "metadata": {},
   "source": [
    "# Disambiguate by taxa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d36274",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_SAMP_SUBSETS_REJECTED_BY_TAXA = {}\n",
    "for taxid in TAXA_LIST:\n",
    "    DF_SAMP_SUBSETS_REJECTED_BY_TAXA[taxid] = {}\n",
    "    for key in DF_SAMP_SUBSETS_ACCEPTED:    \n",
    "        df_rej = DF_SAMP_SUBSETS_ACCEPTED[key].copy()\n",
    "        df_rej.iloc[:,nscreens:] = np.nan\n",
    "        ko_values_rej = {\n",
    "            sample_id: df[df[\"taxid\"] == taxid].groupby(\"ko\")[\"avg_depth\"].sum()\n",
    "            for sample_id, df in contam_dfs.items()\n",
    "        }\n",
    "\n",
    "        for sample_id, series in ko_values_rej.items():\n",
    "            if sample_id in df_rej.index:\n",
    "                for ko, value in series.items():\n",
    "                    if ko in df_rej.columns:\n",
    "                        df_rej.at[sample_id, ko] = value\n",
    "        DF_SAMP_SUBSETS_REJECTED_BY_TAXA[taxid][key] = df_rej\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e507baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "suboutdir = f\"{OUTDIR}/by_taxa\"\n",
    "os.makedirs(suboutdir, exist_ok=True)\n",
    "\n",
    "for taxid in TAXA_LIST:\n",
    "    dftaxa = DF_SAMP_SUBSETS_REJECTED_BY_TAXA[taxid]\n",
    "    for key in dftaxa:\n",
    "        df = dftaxa[key]\n",
    "        df.iloc[:,nscreens:].to_csv(\n",
    "            f\"{suboutdir}/{key}_{taxid}_rejected.csv\", \n",
    "            float_format=\"%.3f\", na_rep=np.nan\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06b0770",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "##  Violin plots (COMPARISON, DISAMBIGUATED)\n",
    "\n",
    "subimgdir = f\"{IMGDIR}/by_taxa\"\n",
    "os.makedirs(subimgdir, exist_ok=True)\n",
    "\n",
    "for category in KO_CATEGORIES:\n",
    "    ko_set = KO_CATEGORY_SETS[category]\n",
    "    ko_labels = [ko + \"\\n\" + DF_KO_INFO.loc[ko, \"SYMBOL\"] for ko in ko_set]\n",
    "    keys = [\"t0_samples\", \"chl_pos_samples\", \"chl_neg_samples\",]\n",
    "\n",
    "    for taxid in TAXA_LIST:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(8,10))\n",
    "\n",
    "        make_violin_plot(\n",
    "            DF_SAMP_SUBSETS_ACCEPTED, ko_set, keys, \n",
    "            ko_labels=ko_labels,\n",
    "            ax=ax,\n",
    "            legend=True,\n",
    "            legend_labels=[k + \" (accepted)\" for k in keys],\n",
    "            colors=colors_acc,\n",
    "            alpha=alpha_acc,\n",
    "            hatch=hatch_acc,\n",
    "        )\n",
    "\n",
    "        make_violin_plot(\n",
    "            DF_SAMP_SUBSETS_REJECTED_BY_TAXA[taxid], ko_set, keys, \n",
    "            ko_labels=ko_labels,\n",
    "            ax=ax,\n",
    "            legend=True,\n",
    "            legend_labels=[k + \" (rejected)\" for k in keys],\n",
    "            colors=colors_rej,\n",
    "            alpha=alpha_rej,\n",
    "            hatch=hatch_rej,\n",
    "        )\n",
    "\n",
    "        spec = TAXA_DF[TAXA_DF[\"taxid\"] == taxid][\"species\"].values[0]\n",
    "        ax.set_title(f\"{category} (accepted vs rejected)\\n {taxid} ({spec})\")\n",
    "\n",
    "        saveas = f\"{subimgdir}/{category.replace(\" \", \"_\")}_comparison_{taxid}.png\"\n",
    "        print(f\"Saving {saveas}\")\n",
    "        plt.savefig(saveas, bbox_inches=\"tight\")\n",
    "        if CLOSE_PLOTS:\n",
    "            plt.close()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb8ed6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
